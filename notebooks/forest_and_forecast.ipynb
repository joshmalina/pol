{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame, get_dummies, concat\n",
    "import requests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from ggplot import *\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict on year, day of month optionally -- those are available but for some reason we aren't modeling on those - of course, predicting on previous values would also be nice but not sure how to integrate this into forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"FCTTIME\": {\n",
    "\t\t\"hour\": \"2\",\"hour_padded\": \"02\",\"min\": \"00\",\"min_unpadded\": \"0\",\"sec\": \"0\",\"year\": \"2015\",\"mon\": \"10\",\"mon_padded\": \"10\",\"mon_abbrev\": \"Oct\",\"mday\": \"3\",\"mday_padded\": \"03\",\"yday\": \"275\",\"isdst\": \"0\",\"epoch\": \"1443808800\",\"pretty\": \"2:00 AM CST on October 03, 2015\",\"civil\": \"2:00 AM\",\"month_name\": \"October\",\"month_name_abbrev\": \"Oct\",\"weekday_name\": \"Saturday\",\"weekday_name_night\": \"Saturday Night\",\"weekday_name_abbrev\": \"Sat\",\"weekday_name_unlang\": \"Saturday\",\"weekday_name_night_unlang\": \"Saturday Night\",\"ampm\": \"AM\",\"tz\": \"\",\"age\": \"\",\"UTCDATE\": \"\"\n",
    "\t\t},\n",
    "\t\t\"temp\": {\"english\": \"56\", \"metric\": \"13\"},\n",
    "\t\t\"dewpoint\": {\"english\": \"43\", \"metric\": \"6\"},\n",
    "\t\t\"condition\": \"Clear\",\n",
    "\t\t\"icon\": \"clear\",\n",
    "\t\t\"icon_url\":\"http://icons.wxug.com/i/c/k/nt_clear.gif\",\n",
    "\t\t\"fctcode\": \"1\",\n",
    "\t\t\"sky\": \"0\",\n",
    "\t\t\"wspd\": {\"english\": \"6\", \"metric\": \"10\"},\n",
    "\t\t\"wdir\": {\"dir\": \"N\", \"degrees\": \"359\"},\n",
    "\t\t\"wx\": \"Clear\",\n",
    "\t\t\"uvi\": \"0\",\n",
    "\t\t\"humidity\": \"61\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class forecast(object):    \n",
    "    \n",
    "    def __init__(self, forestColumnNames, frst):\n",
    "        self.forestColumnNames = forestColumnNames\n",
    "        self.frst = frst\n",
    "        API_KEY = ''\n",
    "        url = 'http://api.wunderground.com/api/'+API_KEY+'/hourly10day/q/Beijing/Beijing.json'\n",
    "        content = requests.get(url).json()\n",
    "        self.raw = content['hourly_forecast']\n",
    "        self.df = self.prepForRF()\n",
    "        \n",
    "    def day_to_int(self, day_string):\n",
    "        dayvals = {\n",
    "            'Sunday': 0,\n",
    "            'Monday': 1,\n",
    "            'Tuesday': 2,\n",
    "            'Wednesday': 3,\n",
    "            'Thursday': 4, \n",
    "            'Friday': 5, \n",
    "            'Saturday': 6\n",
    "        }\n",
    "        return dayvals.get(day_string, 'nothing')\n",
    "        \n",
    "    def extractRow(self, one):   \n",
    "        date = one['FCTTIME']\n",
    "        return dict(year=date['year'], month=date['mon'], day=date['mday'], wday=self.day_to_int(date['weekday_name']), hour=date['hour'], pressurei=one['mslp']['english'], icon=one['icon'], dewpti=one['dewpoint']['english'], hum=one['humidity'], temp=one['temp']['metric'], wdird=one['wdir']['degrees'], wdire=one['wdir']['dir'], wspdm=one['wspd']['metric'])\n",
    "         \n",
    "    def extractRows(self):\n",
    "        return DataFrame([self.extractRow(x) for x in self.raw])\n",
    "    \n",
    "    # make into binary values categorical vars\n",
    "    def categorizeVars(self):\n",
    "        df = self.extractRows()\n",
    "        return pd.concat([df, get_dummies(df.wdire), get_dummies(df.icon)], axis=1)\n",
    "    \n",
    "    def prepForRF(self):\n",
    "        df = self.categorizeVars()\n",
    "        # rename certain vars, E to East, W to West, Month to mon, because of inconsistencies in the wunderground API\n",
    "        df = df.rename(columns={'E':'East', 'W':'West', 'N':'North', 'S':'South', 'month': 'mon', 'temp' : 'tempm'})\n",
    "        df.columns\n",
    "        # drop icon, wdire\n",
    "        # later rebuild the model with day and year\n",
    "        df = df.drop(['icon', 'wdire', 'wdird', 'day', 'year'], axis=1)\n",
    "        df = self.imputeVals(df)\n",
    "        df = self.addPredictions(df)\n",
    "        return df\n",
    "    \n",
    "    def imputeVals(self, df):\n",
    "        # any missing values in the test frame need to be imputed with all zeroes\n",
    "        cols_to_add = self.forestColumnNames - df.columns\n",
    "        for (idx, val) in enumerate(cols_to_add):\n",
    "            df[val] = np.zeros(df.shape[0])        \n",
    "        return df\n",
    "    \n",
    "    def addPredictions(self, df):\n",
    "        df['predictions'] = self.frst.predict(df)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 200 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 450 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "frcast = forecast(X_train.columns, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class forest():\n",
    "    \n",
    "    def __init__(self):\n",
    "        data = pd.read_csv('data.csv')\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.prepData(data)\n",
    "        self.rf = self.buildForest(self.X_train, self.y_train)\n",
    "        \n",
    "    def prepData(self, df):\n",
    "        df = self.catVars(df)\n",
    "        df = self.removeUnusedVars(df)\n",
    "        self.df = df\n",
    "        return self.splitSet(df)\n",
    "        \n",
    "    def catVars(self, df):\n",
    "        wdire_cat = get_dummies(df.wdire)\n",
    "        icon_cat = get_dummies(df.icon)\n",
    "        return concat([df, wdire_cat, icon_cat], axis=1)\n",
    "    \n",
    "    def removeUnusedVars(self, df):\n",
    "        return df.drop(['X', 'conds', 'datetime', 'icon', 'visi', 'wdird', 'wdire', 'Unnamed: 0'], axis=1)\n",
    "    \n",
    "    def splitSet(self, df):\n",
    "        # create training (80%) and test (20%) sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df[df.columns.difference(['Value'])], df.Value, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def buildForest(self, X_train, y_train):\n",
    "        rf = RandomForestRegressor(n_estimators=500, verbose=1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        return rf\n",
    "    \n",
    "    def metrics(self, y_test, X_test, rf):\n",
    "        self.r2 = r2_score(y_test, rf.predict(X_test))\n",
    "        self.mse = np.mean((y_test - rf.predict(X_test))**2)\n",
    "        self.rmse = np.sqrt(mse)\n",
    "    \n",
    "    def plotMetrics(self, rf):\n",
    "        measures = DataFrame({\"feature_importances_\": rf.feature_importances_, \"names\" : X_train.columns})\n",
    "        ggplot(measures, aes(x='names', y='feature_importances_')) + geom_bar(stat='bar') + theme(axis_text_x = element_text(angle = 90, hjust = 1))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:   23.0s\n",
      "[Parallel(n_jobs=1)]: Done 200 jobs       | elapsed:  1.5min\n",
      "[Parallel(n_jobs=1)]: Done 450 jobs       | elapsed:  3.2min\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  3.6min finished\n"
     ]
    }
   ],
   "source": [
    "fr = forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
